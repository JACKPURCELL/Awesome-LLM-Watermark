# Watermark papers 

This repo includes papers about the watermarking for text and images.

https://gitmind.com/app/docs/m4dkhkgz

# Survey
* **A Survey on Detection of LLMs-Generated Content** Preprint
  * Xianjun Yang
  * https://arxiv.org/pdf/2310.15654.pdf

* **WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models.** Prepring.
  * Shangqing Tu, Yuliang Sun, Yushi Bai, Jifan Yu, Lei Hou, Juanzi Li
  * https://arxiv.org/abs/2311.07138
  * Benchmark dataset
 
* **Towards Possibilities & Impossibilities of AI-generated Text Detection: A Survey** Prepring.
  * Anonymous authors
  * https://openreview.net/pdf?id=AXtFeYjboj
 
* **A Survey of Text Watermarking in the Era of Large Language Models.** Preprint. Survey paper.
  * Aiwei Liu, Leyi Pan, Yijian Lu, Jingjing Li, Xuming Hu, Lijie Wen, Irwin King, Philip S. Yu
  * https://arxiv.org/abs/2312.07913  
    
# Attack
* **DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature[DetectGPT]**
  * https://arxiv.org/pdf/2301.11305v1.pdf

* **Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense[retrieval]**
  * https://arxiv.org/pdf/2303.13408.pdf

### Paraphrasing attack(Digger)
* **Can ai-generated text be reliably detected?**
  * https://github.com/vinusankars/Reliability-of-AI-text-detectors

* **Paraphrasing evades detectors of ai-generated text, but retrieval is an effective defense**
  * https://github.com/martiansideofthemoon/ai-detection-paraphrases
 
### Perturbation attack
* **Watermarks in the Sand: Impossibility of Strong Watermarking for Generative Models** Preprint
  * Hanlin Zhang
  * https://arxiv.org/pdf/2311.04378.pdf


### Extraction attack
* **On the learnability of watermarks for language models**

### Copy-paste attack
* **On the reliability of watermarks for large language models**
  * https://github.com/jwkirchenbauer/lm-watermarking

### Text-bugger attack
* **Textbugger: Generating adversarial text against real-world applications**
  * https://github.com/thunlp/OpenAttack

# Text watermark
* **Towards Optimal Statistical Watermarking.** Preprint.
  
  * Baihe Huang, Banghua Zhu, Hanlin Zhu, Jason D. Lee, Jiantao Jiao, Michael I. Jordan
  * https://arxiv.org/abs/2312.07930


* **On the Learnability of Watermarks for Language Models.** Preprint.

  * Chenchen Gu, Xiang Lisa Li, Percy Liang, Tatsunori Hashimoto

  * https://arxiv.org/abs/2312.04469
* **New Evaluation Metrics Capture Quality Degradation due to LLM Watermarking.** Preprint.
  
  * Karanpartap Singh, James Zou

  * https://arxiv.org/abs/2312.02382
  
* **Mark My Words: Analyzing and Evaluating Language Model Watermarks.** Preprint.

  * Julien Piet, Chawin Sitawarin, Vivian Fang, Norman Mu, David Wagner

  * https://arxiv.org/abs/2312.00273

* **I Know You Did Not Write That! A Sampling Based Watermarking Method for Identifying Machine Generated Text.** Preprint.

  * Kaan Efe Keleş, Ömer Kaan Gürbüz, Mucahid Kutlu

  * https://arxiv.org/abs/2311.18054

* **Improving the Generation Quality of Watermarked Large Language Models via Word Importance Scoring.** Preprint

  * Yuhang Li, Yihan Wang, Zhouxing Shi, Cho-Jui Hsieh
  * https://arxiv.org/abs/2311.09668

* **Performance Trade-offs of Watermarking Large Language Models.** Preprint.
  * Anirudh Ajith, Sameer Singh, Danish Pruthi
  * https://arxiv.org/abs/2311.09816

* **X-Mark: Towards Lossless Watermarking Through Lexical Redundancy.** Preprint.
  * Liang Chen, Yatao Bian, Yang Deng, Shuaiyi Li, Bingzhe Wu, Peilin Zhao, Kam-fai Wong
  * https://arxiv.org/abs/2311.09832

* **Publicly Detectable Watermarking for Language Models**
 * https://eprint.iacr.org/2023/1661.pdf
 * * Compare with Undetectable Watermarks for Language Models

* **Watermarks in the Sand: Impossibility of Strong Watermarking for Generative Models.** Preprint.
  
  * Hanlin Zhang, Benjamin L. Edelman, Danilo Francati, Daniele Venturi, Giuseppe Ateniese, Boaz Barak

  * https://arxiv.org/abs/2311.04378

* **REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models.** Preprint[Training-based, modified the embedding information, The idea is from "Undetectable Watermarks for Language Models"]
  * Ruisi Zhang, Shehzeen Samarah Hussain, Paarth Neekhara, Farinaz Koushanfar
  * https://arxiv.org/abs/2310.12362

* **PLMmark: A Secure and Robust Black-Box Watermarking Framework for Pre-trained Language Models** Preprint.
  * Peixuan Li
  * https://ojs.aaai.org/index.php/AAAI/article/view/26750


* **Embarrassingly Simple Text Watermarks.** Preprint.
  * Ryoma Sato, Yuki Takezawa, Han Bao, Kenta Niwa, Makoto Yamada
  * https://arxiv.org/abs/2310.08920

* **Necessary and Sufficient Watermark for Large Language Models.** Preprint.
  * Yuki Takezawa, Ryoma Sato, Han Bao, Kenta Niwa, Makoto Yamada
  * https://arxiv.org/abs/2310.00833

* **Functional Invariants to Watermark Large Transformers.** Preprint.
  * Fernandez Pierre, Couairon Guillaume, Furon Teddy, Douze Matthijs
  * https://arxiv.org/abs/2310.11446

* **Watermarking LLMs with Weight Quantization.** EMNLP2023 findings.[Training-based, Weight Quantization]
  * Linyang Li, Botian Jiang, Pengyu Wang, Ke Ren, Hang Yan, Xipeng Qiu
  * https://arxiv.org/abs/2310.11237
  * https://github.com/Twilight92z/Quantize-Watermark

* **DiPmark: A Stealthy, Efficient and Resilient Watermark for Large Language Models.** Preprint.[free-distribution,a update for baseline A Watermark for Large Language Models]
  * Yihan Wu, Zhengmian Hu, Hongyang Zhang, Heng Huang
  * https://arxiv.org/abs/2310.07710

* **A Semantic Invariant Robust Watermark for Large Language Models.** Preprint.[submodel Training-based, Use another model to generate the watermark]
  * Aiwei Liu, Leyi Pan, Xuming Hu, Shiao Meng, Lijie Wen
  * https://arxiv.org/abs/2310.06356
  
* **SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation.** Preprint.
  * Abe Bohan Hou, Jingyu Zhang, Tianxing He, Yichen Wang, Yung-Sung Chuang, Hongwei Wang, Lingfeng Shen, Benjamin Van Durme, Daniel Khashabi, Yulia Tsvetkov
  * https://arxiv.org/abs/2310.03991

* **Advancing Beyond Identification: Multi-bit Watermark for Language Models.** Preprint.[multi-bit]
  * KiYoon Yoo, Wonhyuk Ahn, Nojun Kwak.
  * https://arxiv.org/abs/2308.00221
* **Three Bricks to Consolidate Watermarks for Large Language Models.** Preprint.[multi-bit]
  * Pierre Fernandez, Antoine Chaffin, Karim Tit, Vivien Chappelier, Teddy Furon.
  * https://arxiv.org/abs/2308.00113
  * https://github.com/facebookresearch/three_bricks
* **Towards Codable Text Watermarking for Large Language Models.** Preprint.
  * Lean Wang, Wenkai Yang, Deli Chen, Hao Zhou, Yankai Lin, Fandong Meng, Jie Zhou, Xu Sun.
  * https://arxiv.org/abs/2307.15992
  * https://github.com/lancopku/codable-watermarking-for-llm
* **A Private Watermark for Large Language Models.** Preprint.[free/  submodel Training-based, Use another model to generate the watermark]
  * Aiwei Liu, Leyi Pan, Xuming Hu, Shu'ang Li, Lijie Wen, Irwin King, Philip S. Yu. 
  * https://arxiv.org/abs/2307.16230
  * https://github.com/THU-BPM/private_watermark
* **Robust Distortion-free Watermarks for Language Models.** Preprint.[free-Sampling]
  * Rohith Kuditipudi John Thickstun Tatsunori Hashimoto Percy Liang.
  * https://arxiv.org/abs/2307.15593
  * https://github.com/jthickstun/watermark
* **Watermarking Conditional Text Generation for AI Detection: Unveiling Challenges and a Semantic-Aware Watermark Remedy.** Preprint.[Training-free, distribution]
  * Yu Fu, Deyi Xiong, Yue Dong.
  * https://arxiv.org/abs/2307.13808
* **Provable Robust Watermarking for AI-Generated Text.** Preprint.[Modification of the Distribution]
  * Xuandong Zhao, Prabhanjan Ananth, Lei Li, Yu-Xiang Wang.
  * https://arxiv.org/abs/2306.17439
  * https://github.com/XuandongZhao/Unigram-Watermark
* **On the Reliability of Watermarks for Large Language Models.** Preprint.[Modification of the Distribution]
  * John Kirchenbauer, Jonas Geiping, Yuxin Wen, Manli Shu, Khalid Saifullah, Kezhi Kong, Kasun Fernando, Aniruddha Saha, Micah Goldblum, Tom Goldstein.
  * https://arxiv.org/abs/2306.04634
  * https://github.com/jwkirchenbauer/lm-watermarking
* **Undetectable Watermarks for Language Models.** Preprint.[Modification of the Sampling]
  * Miranda Christ, Sam Gunn, Or Zamir.
  * https://arxiv.org/abs/2306.09194
* **Watermarking GPT Outputs ** Preprint.[Modification of the Sampling]
  * Scott Aaronson and Hendrik Kirchner .
  * https://www.scottaaronson.com/talks/watermark.ppt
* **Watermarking Text Data on Large Language Models for Dataset Copyright Protection.** Preprint.
  * Yixin Liu, Hongsheng Hu, Xuyun Zhang, Lichao Sun.
  * https://arxiv.org/abs/2305.13257
* **Baselines for Identifying Watermarked Large Language Models.** Preprint.
  * Leonard Tang, Gavin Uberti, Tom Shlomi.
  * https://arxiv.org/abs/2305.18456
* **Who Wrote this Code? Watermarking for Code Generation.** Preprint.
  * Taehyun Lee, Seokhee Hong, Jaewoo Ahn, Ilgee Hong, Hwaran Lee, Sangdoo Yun, Jamin Shin, Gunhee Kim.
  * https://arxiv.org/abs/2305.15060
* **Robust Multi-bit Natural Language Watermarking through Invariant Features.** ACL 2023.[multi-bit]
  * KiYoon Yoo, Wonhyuk Ahn, Jiho Jang, Nojun Kwak.
  * https://arxiv.org/abs/2305.01904
  * https://github.com/bangawayoo/nlp-watermarking
* **Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark.** ACL 2023.
  * Wenjun Peng, Jingwei Yi, Fangzhao Wu, Shangxi Wu, Bin Zhu, Lingjuan Lyu, Binxing Jiao, Tong Xu, Guangzhong Sun, Xing Xie.
  * https://arxiv.org/abs/2305.10036
  * https://github.com/yjw1029/EmbMarker
* **Watermarking Text Generated by Black-Box Language Models.** Preprint.
  * Xi Yang, Kejiang Chen, Weiming Zhang, Chang Liu, Yuang Qi, Jie Zhang, Han Fang, Nenghai Yu.
  * https://arxiv.org/abs/2305.08883
  * https://github.com/Kiode/Text_Watermark_Language_Models
* **Protecting Language Generation Models via Invisible Watermarking.** ICML 2023.[free-distrubution]
  * Xuandong Zhao, Yu-Xiang Wang, Lei Li.
  * https://arxiv.org/abs/2302.03162
  * https://github.com/XuandongZhao/Ginsew
* **A Watermark for Large Language Models.** ICML 2023. Outstanding Paper Award[Modification of the Distribution baseline]
  * John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, Tom Goldstein.
  * https://arxiv.org/abs/2301.10226
  * https://github.com/jwkirchenbauer/lm-watermarking
* **Distillation-Resistant Watermarking for Model Protection in NLP.** EMNLP 2022
  * Xuandong Zhao, Lei Li, Yu-Xiang Wang.
  * https://arxiv.org/abs/2210.03312
  * https://github.com/XuandongZhao/DRW
* **CATER: Intellectual Property Protection on Text Generation APIs via Conditional Watermarks.** NeurIPS 2022
  * Xuanli He, Qiongkai Xu, Yi Zeng, Lingjuan Lyu, Fangzhao Wu, Jiwei Li, Ruoxi Jia.
  * https://arxiv.org/abs/2209.08773
  * https://github.com/xlhex/cater_neurips
* **Watermarking the Outputs of Structured Prediction with an application in Statistical Machine Translation.** EMNLP 2011
  * Ashish Venugopal, Jakob Uszkoreit, David Talbot, Franz Och, Juri Ganitkevitch.
  * https://aclanthology.org/D11-1126/

    
## Image watermark
* **Invisible Image Watermarks Are Provably Removable Using Generative AI.** Preprint.
  * Xuandong Zhao, Kexun Zhang, Zihao Su, Saastha Vasan, Ilya Grishchenko, Christopher Kruegel, Giovanni Vigna, Yu-Xiang Wang, Lei Li.
  * https://arxiv.org/abs/2306.01953
* **Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust.** Preprint.
  * Yuxin Wen, John Kirchenbauer, Jonas Geiping, Tom Goldstein.
  * https://arxiv.org/abs/2305.20030
* **Evading Watermark based Detection of AI-Generated Content.** CCS 2023.
  * Zhengyuan Jiang, Jinghuai Zhang, Neil Zhenqiang Gong.
  * https://arxiv.org/abs/2305.03807
* **The Stable Signature: Rooting Watermarks in Latent Diffusion Models.** ICCV 2023.
  * Pierre Fernandez, Guillaume Couairon, Hervé Jégou, Matthijs Douze, Teddy Furon.
  * https://arxiv.org/abs/2303.15435
* **Watermarking Images in Self-Supervised Latent Spaces.** ICASSP 2022.
  * Pierre Fernandez, Alexandre Sablayrolles, Teddy Furon, Hervé Jégou, Matthijs Douze.
  * https://arxiv.org/abs/2112.09581
    
# Contributing to this paper list

First, think about which category the work should belong to.

Second, use the same format as the others to describe the work.
